{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The command below means that the output of multiple commands in a cell will be \n",
    "# output at once.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing the new data set\n",
    "home_folder = '/Users/anthonymiyoro/Documents/code/DataTho/'\n",
    "\n",
    "#Read dataset\n",
    "train_modified = pd.read_csv(home_folder + 'train_modified.csv')\n",
    "test_bundas = pd.read_csv(home_folder + 'bundas_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how well our model generalizes, we need to split our data into a test and training set. In order to get a true prediction, we can't show our model the test labels. Instead we just ask the model to score based upon the test explanatory variables.\n",
    "In order to get to this, we split the dataframe into a test and train.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we additionally need to seperate the explanatory features from our outcome feature.\n",
    "To do this we need to create four subsets of data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train: the explanatory features to train the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train: the outcome feature associated with the training features - In this case, these are the loan amounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test: the explanatory features to test the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test: the true Y of the target features associated with the testing geatures - again, in this case, these are the loan amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we will use the sklearn model selection function train_test_split. If you look back to the top of this page, we imported this function at the beginning of the notebook.\n",
    "The names used below (X_train, X_test, y_train, y_test) are the conventions used in industry for train and test data so you will continue to see them repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Item_ID', 'Weight', 'Visibility', 'Max_Price',\n",
      "       'Store_Establishment_Year', 'Item_Store_Sales', 'FatContent_LF',\n",
      "       'FatContent_Low_Fat', 'FatContent_Regular', 'FatContent_low_fat',\n",
      "       'FatContent_reg', 'Category_Baking_Goods', 'Category_Breads',\n",
      "       'Category_Breakfast', 'Category_Canned', 'Category_Dairy',\n",
      "       'Category_Frozen_Foods', 'Category_Fruits_and_Vegetables',\n",
      "       'Category_Hard_Drinks', 'Category_Health_and_Hygiene',\n",
      "       'Category_Household', 'Category_Meat', 'Category_Others',\n",
      "       'Category_Seafood', 'Category_Snack_Foods', 'Category_Soft_Drinks',\n",
      "       'Category_Starchy_Foods', 'Store_Size_High', 'Store_Size_Medium',\n",
      "       'Store_Size_Small', 'Store_Location_Type_Tier_1',\n",
      "       'Store_Location_Type_Tier_2', 'Store_Location_Type_Tier_3',\n",
      "       'Store_Type_Grocery_Store', 'Store_Type_Supermarket_Type1',\n",
      "       'Store_Type_Supermarket_Type2', 'Store_Type_Supermarket_Type3',\n",
      "       'Store_ID_OUT013', 'Store_ID_OUT018', 'Store_ID_OUT019',\n",
      "       'Store_ID_OUT027', 'Store_ID_OUT035', 'Store_ID_OUT046',\n",
      "       'Store_ID_OUT049'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_modified.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then remove the Item_ID feature as it does not correlate to Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified = train_modified.drop('Item_ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4890"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(train_modified, test_size=0.2)\n",
    "len(train)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scikit learn package requires that the explanatory variables are stored seperately from the outcome variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training array = all the features but not the target\n",
    "# and a training test array = the results of the target variable for the training array\n",
    "rf_trainY = train_modified['Item_Store_Sales']\n",
    "rf_trainX = train_modified.drop('Item_Store_Sales', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4890"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4890"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rf_trainX, rf_trainY, test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train)\n",
    "len(X_test)\n",
    "len(y_train)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into some of the more sophisticated models, let's first try an individual Decision Tree and see how it performs. \n",
    "\n",
    "After training the model, we will be able to assess it's performance by using sklearns useful method .score, which calculates the r2 value for the data provided. \n",
    "\n",
    "We will first print out the r2 score for the training data, and then will print out the r2 score for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.15780932934084002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Step 1: Initiating the DecisionTreeRegressor algorithm\n",
    "decision_regressor = DecisionTreeRegressor(random_state=0)\n",
    "# Step 2: Training the algorithm using the X_train dataset of features and y_train, the associated target features\n",
    "decision_regressor.fit(X_train, y_train)\n",
    "# Step 3: Calculating the score of the predictive power on the training and testing dataset.\n",
    "dt_training_score = decision_regressor.score(X_train, y_train)\n",
    "dt_testing_score = decision_regressor.score(X_test, y_test)\n",
    "print(\"Train score: \" + str(dt_training_score))\n",
    "print(\"Test score: \" + str(dt_testing_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
